{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs26 \cf0 Reasoning about object affordances allows an autonomous\
agent to perform generalised manipulation tasks\
among object instances. While current approaches to grasp\
affordance estimation are effective, they are limited to a single\
hypothesis. We present an approach for detection and extraction\
of multiple grasp affordances on an object via visual input. We\
define semantics as a combination of multiple attributes, which\
yields benefits in terms of generalisation for grasp affordance\
prediction. We use Markov Logic Networks to build a knowledge\
base graph representation to obtain a probability distribution\
of grasp affordances for an object. To harvest the knowledge\
base, we collect and make available a novel dataset that relates\
different semantic attributes. We achieve reliable mappings\
of the predicted grasp affordances on the object by learning\
prototypical grasping patches from several examples. We show\
our method\'92s generalisation capabilities on grasp affordance\
prediction for novel instances and compare with similar methods\
in the literature. Moreover, using a robotic platform, on simulated\
and real scenarios, we evaluate the success of the grasping task\
when conditioned on the grasp affordance prediction.}