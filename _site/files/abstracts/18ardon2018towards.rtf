{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\qj\partightenfactor0

\f0\fs24 \cf0 Artificial Intelligence is essential to achieve a reliable human-robot\
interaction, especially when it comes to manipulation\
tasks. Most of the state-of-the-art literature explores\
robotics grasping methods by focusing on the target object or\
the robot\'92s morphology, without including the environment.\
When it comes to human cognitive development approaches,\
these physical qualities are not only inferred from the object,\
but also from the semantic characteristics of the surroundings.\
The same analogy can be used in robotic affordances\
for improving objects grasps, where the perceived physical\
qualities of the objects give valuable information about the\
possible manipulation actions. This work proposes a framework\
able to reason on the object affordances and grasping\
regions. Each calculated grasping area is the result of a sequence\
of concrete ranked decisions based on the inference\
of different highly related attributes. The results show that\
the system is able to infer on good grasping areas depending\
on its affordance without having any a-priori knowledge on\
the shape nor the grasping points.}